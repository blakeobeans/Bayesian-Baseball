table(data$pit)# interesting margins, assume 1 per game
hist(data$score, prob=TRUE) #dist of scores
lines(density(data$score))
shapiro.test(data$score) #passes normality
#sort data
data <- data[order(data$opp_team),] #sort by team, note imbalance
'What is Stan? Stan is a program that does monte carlo simulation, specifically,
Hamiltonian Monte Carlo with a no u-turn sample, to calculate posterior distributions
through stochastic (as opposed to analytical means). Hamiltonian monte carlo is less
likely to get stuck as local minimums, which is a problem when dealing with
multi-modal posteriors.https://chi-feng.github.io/mcmc-demo/'
set.seed(1234)
model <- map2stan(
alist(
score ~ dnorm( mu , sigma ) , #fair assumption given data
mu <- a[opp_team], #this is the regression equation/likelihood function
a[opp_team] ~ dnorm( 0 , 4 ), #what choice prior
sigma ~ dcauchy(0, 2.5) #prior to sigma
),
data=data, iter=6000, warmup=3000, chains=4)
#coefficients
head(precis(model, depth=2, prob=.95)) #OK that 0 in CI, similar sigma
#sample from posterior
postmodel <- extract.samples( model, n=5000)
postmodel.df <- as.data.frame(postmodel)
str(postmodel)
#Prior and Posterior- Note: does not account for group-level variance
par(mfrow=c(1,1))
dens( postmodel$a[,7], show.HPDI=0.95, main= "Cubs vs. Angels- Posterior of Mean Score") #POSTERIOR dist of means
x<-seq(from=-4, to=10, by=.1)
lines(x, dnorm(x, 0, 4), col="blue") #PRIOR Distribution
#Simulating posterior distributions all opposing teams
d.pred <- list(opp_team = 1:20)
#sim function to plot distribution of scores- This accounts for variance
sim.model <- sim( model , data=d.pred)
str(sim.model)
#CI for scores by team
pred.p <- apply( sim.model, 2 , mean); pred.p
pred.p.PI <- apply( sim.model, 2 , HPDI, prob=.95 ); pred.p.PI
pred.p2 <-as.data.frame(pred.p); head(pred.p2)
pred.p.PI2 <-as.data.frame(pred.p.PI); head(pred.p.PI2)
pred.p.PI2 <- t(pred.p.PI2); head(pred.p.PI2)
d<-cbind(pred.p2, pred.p.PI2, 1:20)
names(d) <- c("mean", "lower", "upper", "games"); head(d)
#Posterior Distributions
plot(d$games, d$mean, type = "n", xlab = "Opposing Team", ylab = "Score", ylim=c(-15,15), main= "MLM Regression")
segments(d$games, d$lower, d$games, d$upper)
abline(h = 0, col = "red")
points(data$opp_team, data$score, col = "red", pch=4)
points(d$games, d$mean, col = "blue", pch=19)
#compare intervals to standard regression
plot(lmdata$opp_team, lmdata$mean, type = "n", ylim=c(-15, 15), main ="OLS Regression") #note enlarging y-axis
segments(lmdata$opp_team, lmdata$mean + lmdata$lwr, lmdata$opp_team, lmdata$mean + lmdata$upr)
points(data$opp_team, data$score, col = "red", pch=4)
points(lmdata$opp_team, lmdata$mean, col = "blue", pch=19)
abline(h = 0, col = "red")
#Effect of MLM on mean, pooling effect across tanks
plot(d$games, d$mean, type = "n", xlab = "match", ylab = "score", ylim=c(-5,5), main="Pooling Effect of MLM")
points(lmdata$opp_team, lmdata$mean, col = "red", pch=1) #mean for standard regression
points(d$games, d$mean, col = "blue", pch=19) #mean for MLM
abline(h=mean(data$score), col = "blue")
#MLM. Pitcher ERA, WL record, how many levels in baseball?
#Note hyperparameters
standata <- data[,c("score", "opp_team", "pitera_norm", "wl_norm")]
set.seed(1234)
model2 <- map2stan(
alist(
score ~ dnorm( mu , sigma ) ,
mu <- a + a_team[opp_team] + b * pitera_norm + c * wl_norm,
sigma ~ dcauchy(0, 2.5),
a ~ dnorm(0,3),
a_team[opp_team] ~ dnorm( ai , as ), #adaptive prior from the data
ai ~ dnorm(0, 1),
as ~ dcauchy(0,2),
b ~ dnorm( 0, 1 ),
c ~ dnorm(0,1)
),
data=standata, iter=12000, warmup=3000, chains=4, cores=4)
#comparing models
compare(model, model2)
#coefficients
precis(model2, depth=2, prob=.95) #n_eff: number effective samples. R-hat: convergence to target dist.
coef <- precis(model2, depth=2, prob=.95)
coef2 <- slice(coef, c(1:2, 23:26))
variable <- c("sigma", "a", "ai", "as", "b", "c")
coef2 <- cbind(coef2, variable)
coef2 <-as.data.frame(coef2)
coef2 <- select(coef2, "variable", "mean", "sd", "2.5%", "97.5%", "n_eff", "Rhat")
#trace plot. Using monte carlo methods to "hill climb" and find the most likely parameter.
plot(model2)
d.pred <- list(
pitera_norm = -.929, #Hendricks
wl_norm = 1.29, #WL normalized for CLE (from WL dataset)
opp_team = 0) #placeholder
#Posterior Simulation
set.seed(1234)
sim.model <- sim( model2 , data=d.pred, n=12000)
sim <- as.data.frame(sim.model)
#Posterior Statistics
pred.p.mean <- apply( sim , 2 , mean ); pred.p.mean
pred.p.PI <- apply( sim, 2 , PI , prob=0.95 ); pred.p.PI
#Plot
par(mfrow=c(1,1))
sim <- as.data.frame(sim.model)
#Posterior Statistics
pred.p.mean <- apply( sim , 2 , mean ); pred.p.mean
pred.p.PI <- apply( sim, 2 , PI , prob=0.95 ); pred.p.PI
#Plot
par(mfrow=c(1,1))
histgm <- hist(sim$V1, breaks=100, prob=TRUE, main="Simulated Games", xlab="Score") #Distribution of predicted scores
plot(histgm, col=ifelse(histgm$breaks >= 0, "green", "red"), main="Posterior Distribution of Outcomes Against CLE (Game 1)", xlab="Score", xlim=c(-12,12))
histgm <- hist(sim$V1, breaks=100, prob=TRUE, main="Simulated Games", xlab="Score") #Distribution of predicted scores
plot(histgm, col=ifelse(histgm$breaks >= 0, "green", "red"), main="Posterior Distribution of Outcomes Against CLE (Game 1)", xlab="Score", xlim=c(-12,12))
abline(v=0, col="blue")
histgm <- hist(sim$V1, breaks=100, prob=TRUE, main="Simulated Games", xlab="Score") #Distribution of predicted scores
histgm$counts=histgm$counts/sum(histgm$counts)
plot(histgm, col=ifelse(histgm$breaks >= 0, "green", "red"), main="Posterior Distribution of Outcomes Against CLE (Game 1)", xlab="Score", xlim=c(-12,12))
plot(histgm, col=ifelse(histgm$breaks >= 0, "green", "red"), main="Posterior Distribution of Outcomes Against CLE (Game 1)", xlab="Score", xlim=c(-12,12))
library(tidyverse)
library(rethinking) #Web page, YouTube, Book
library(car) #regression diagnostics
#Data
#2016 overview: Inherent unpredictability: CHC lost 1/3 of games
#Objective is to predict who wins a game. Build model at level of a particular team.
#CHC schedule overview.
urlfile<-'https://raw.githubusercontent.com/blakeobeans/Bayesian-Baseball/master/Cubs/Season/cubs.csv'
data<-read.csv(urlfile)
#Pitcher Stats
urlfile<-'https://raw.githubusercontent.com/blakeobeans/Bayesian-Baseball/master/Cubs/Pitching/pitching.csv'
pitcher<-read.csv(urlfile)
data<- left_join(data, pitcher,by="Pit")
#WL Record
urlfile<-'https://raw.githubusercontent.com/blakeobeans/Bayesian-Baseball/master/Cubs/Team%20Rankings/rankings.csv'
WL<-read.csv(urlfile)
data<- left_join(data, WL,by="Opp")
#Transform Data
data$score <- data$R-data$RA #Positive score indicates Giants win. Beats logistic. No ties.
data$opp_team <- coerce_index(data$Opp) #ID for team (function from rethinking)
data$pit_id <- coerce_index(data$Pit) #Home pitcher
names(data) <- c("tm", "opp", "R", "RA", "pit", "pitera", "wl", "score",  "opp_team", "pit_id")
data$pitera_norm <-  (data$pitera - mean(data$pitera))/sd(data$pitera) #normalize ERA
data$wl_norm <-  (data$wl - mean(data$wl))/sd(data$wl) #normalize WL
data <- as.data.frame(data)
#Summary Stats
length(unique(data$opp_team)) # number of opposing teams; note 29 other in MLB
length(unique(data$pit)) # number of cubs pitchers
table(data$pit)# interesting margins, assume 1 per game
hist(data$score, prob=TRUE) #dist of scores
lines(density(data$score))
shapiro.test(data$score) #passes normality
#sort data
data <- data[order(data$opp_team),] #sort by team, note imbalance
#Linear Model 1- Team as Factor, no intercept. Not a bad fit!
lm1 <- lm(score ~ factor(opp) -1 , data= data); summary(lm1)
#Residual Plot
layout(matrix(c(1,2,3,4),2,2)) # optional 4 graphs/page
par(mfrow=c(2,2)) #better ordering of graphs
plot(lm1, which = 1:4)
shapiro.test(lm1$residuals)
#Predicting scores- factors, so not line of best fit
teams <- unique(data$opp)
newdata = data.frame(factor(teams)); names(newdata) <- 'opp'
lmdata <- predict(lm1, newdata, interval="predict")
games <- 1:20
lmdata <- as.data.frame(cbind(lmdata, 1:20))
names(lmdata) <- c("mean", "lwr", "upr", "opp_team"); head(lmdata)
#Plotting 95% intervals for each opposing team
par(mfrow=c(1,1))
plot(lmdata$opp_team, lmdata$mean, type = "n", ylim=c(-15, 15), main ="OLS Regression") #note enlarging y-axis
segments(lmdata$opp_team, lmdata$mean + lmdata$lwr, lmdata$opp_team, lmdata$mean + lmdata$upr)
points(data$opp_team, data$score, col = "red", pch=4)
points(lmdata$opp_team, lmdata$mean, col = "blue", pch=19)
abline(h = 0, col = "red")
'What is Stan? Stan is a program that does monte carlo simulation, specifically,
Hamiltonian Monte Carlo with a no u-turn sample, to calculate posterior distributions
through stochastic (as opposed to analytical means). Hamiltonian monte carlo is less
likely to get stuck as local minimums, which is a problem when dealing with
multi-modal posteriors.https://chi-feng.github.io/mcmc-demo/'
set.seed(1234)
model <- map2stan(
alist(
score ~ dnorm( mu , sigma ) , #fair assumption given data
mu <- a[opp_team], #this is the regression equation/likelihood function
a[opp_team] ~ dnorm( 0 , 4 ), #what choice prior
sigma ~ dcauchy(0, 2.5) #prior to sigma
),
data=data, iter=6000, warmup=3000, chains=4)
#coefficients
head(precis(model, depth=2, prob=.95)) #OK that 0 in CI, similar sigma
#sample from posterior
postmodel <- extract.samples( model, n=5000)
postmodel.df <- as.data.frame(postmodel)
str(postmodel)
#Prior and Posterior- Note: does not account for group-level variance
par(mfrow=c(1,1))
dens( postmodel$a[,7], show.HPDI=0.95, main= "Cubs vs. Angels- Posterior of Mean Score") #POSTERIOR dist of means
x<-seq(from=-4, to=10, by=.1)
lines(x, dnorm(x, 0, 4), col="blue") #PRIOR Distribution
#Simulating posterior distributions all opposing teams
d.pred <- list(opp_team = 1:20)
#sim function to plot distribution of scores- This accounts for variance
sim.model <- sim( model , data=d.pred)
str(sim.model)
#CI for scores by team
pred.p <- apply( sim.model, 2 , mean); pred.p
pred.p.PI <- apply( sim.model, 2 , HPDI, prob=.95 ); pred.p.PI
pred.p2 <-as.data.frame(pred.p); head(pred.p2)
pred.p.PI2 <-as.data.frame(pred.p.PI); head(pred.p.PI2)
pred.p.PI2 <- t(pred.p.PI2); head(pred.p.PI2)
d<-cbind(pred.p2, pred.p.PI2, 1:20)
names(d) <- c("mean", "lower", "upper", "games"); head(d)
#Posterior Distributions
plot(d$games, d$mean, type = "n", xlab = "Opposing Team", ylab = "Score", ylim=c(-15,15), main= "MLM Regression")
segments(d$games, d$lower, d$games, d$upper)
abline(h = 0, col = "red")
points(data$opp_team, data$score, col = "red", pch=4)
points(d$games, d$mean, col = "blue", pch=19)
#compare intervals to standard regression
plot(lmdata$opp_team, lmdata$mean, type = "n", ylim=c(-15, 15), main ="OLS Regression") #note enlarging y-axis
segments(lmdata$opp_team, lmdata$mean + lmdata$lwr, lmdata$opp_team, lmdata$mean + lmdata$upr)
points(data$opp_team, data$score, col = "red", pch=4)
points(lmdata$opp_team, lmdata$mean, col = "blue", pch=19)
abline(h = 0, col = "red")
#Effect of MLM on mean, pooling effect across tanks
plot(d$games, d$mean, type = "n", xlab = "match", ylab = "score", ylim=c(-5,5), main="Pooling Effect of MLM")
points(lmdata$opp_team, lmdata$mean, col = "red", pch=1) #mean for standard regression
points(d$games, d$mean, col = "blue", pch=19) #mean for MLM
abline(h=mean(data$score), col = "blue")
#MLM. Pitcher ERA, WL record, how many levels in baseball?
#Note hyperparameters
standata <- data[,c("score", "opp_team", "pitera_norm", "wl_norm")]
set.seed(1234)
model2 <- map2stan(
alist(
score ~ dnorm( mu , sigma ) ,
mu <- a + a_team[opp_team] + b * pitera_norm + c * wl_norm,
sigma ~ dcauchy(0, 2.5),
a ~ dnorm(0,3),
a_team[opp_team] ~ dnorm( ai , as ), #adaptive prior from the data
ai ~ dnorm(0, 1),
as ~ dcauchy(0,2),
b ~ dnorm( 0, 1 ),
c ~ dnorm(0,1)
),
data=standata, iter=12000, warmup=3000, chains=4, cores=4)
#comparing models
compare(model, model2)
#coefficients
precis(model2, depth=2, prob=.95) #n_eff: number effective samples. R-hat: convergence to target dist.
coef <- precis(model2, depth=2, prob=.95)
coef2 <- slice(coef, c(1:2, 23:26))
variable <- c("sigma", "a", "ai", "as", "b", "c")
coef2 <- cbind(coef2, variable)
coef2 <-as.data.frame(coef2)
coef2 <- select(coef2, "variable", "mean", "sd", "2.5%", "97.5%", "n_eff", "Rhat")
#trace plot. Using monte carlo methods to "hill climb" and find the most likely parameter.
plot(model2)
#Predicting Game 1
d.pred <- list(
pitera_norm = -.929, #Hendricks
wl_norm = 1.29, #WL normalized for CLE (from WL dataset)
opp_team = 0) #placeholder
#Posterior Simulation
set.seed(1234)
sim.model <- sim( model2 , data=d.pred, n=12000)
sim <- as.data.frame(sim.model)
#Posterior Statistics
pred.p.mean <- apply( sim , 2 , mean ); pred.p.mean
pred.p.PI <- apply( sim, 2 , PI , prob=0.95 ); pred.p.PI
#Plot
par(mfrow=c(1,1))
histgm <- hist(sim$V1, breaks=100, prob=TRUE, main="Simulated Games", xlab="Score") #Distribution of predicted scores
histgm$counts=histgm$counts/sum(histgm$counts)
plot(histgm, col=ifelse(histgm$breaks >= 0, "green", "red"), main="Posterior Distribution of Outcomes Against CLE (Game 1)", xlab="Score", xlim=c(-12,12))
abline(v=0, col="blue")
prob_success <- sum(sim$V1 > 0)/nrow(sim); prob_success #percent of scores that are wins
sum(sim$V1 < 0)/nrow(sim) #percent of scores that are losses
#Win 4 out of 7
dbinom(4, size=7, prob=prob_success) + dbinom(5, size=7, prob=prob_success) + dbinom(6, size=7, prob=prob_success)+ dbinom(7, size=7, prob=prob_success)
pbinom(3, size=7, prob=prob_success, lower.tail = FALSE)
#Calculate the "Bayesian" R^2
library(rstanarm)
bayes_R2 <- function(fit) {
y <- get_y(fit)
ypred <- posterior_linpred(fit)
e <- -1 * sweep(ypred, 2, y)
var_ypred <- apply(ypred, 1, var)
var_e <- apply(e, 1, var)
var_ypred / (var_ypred + var_e)
}
bayes_r2
bayes_R2
#rstanarm model
M1 <- stan_lmer(score ~ wl_norm + pitera_norm + (1 | opp_team), data=data)
print(median(bayes_R2(M1)))
#Ratio of Variances (using lme4 package)
library(lme4)
fit1 <- lmer(score ~ wl_norm + pitera_norm + (1 |opp_team), data = data, REML = FALSE)
summary(fit1)
.256/17.23
#Shiny App
library(rstan)
library(shinystan)
library(rsconnect)
linkagecode <- stancode(model2)
linkagecode <- stancode(model2)
set.seed(1234)
model_obj <- stan_model(model_code = linkagecode, model_name = "BayesianBaseball")
dat <- list()
dat$score <- standata$score
dat$opp_team <- standata$opp_team
dat$wl_norm <- standata$wl_norm
dat$pitera_norm <- standata$pitera_norm
dat$N <- 161
dat$N_opp_team <- 20
fit <- sampling(model_obj, data = dat, iter=6000, warmup=3000, chains = 4, pars="mu", include=FALSE)
print(fit)
shinyfit<-as.shinystan(fit)
deploy_shinystan(shinyfit, "BayesianBaseball")
library(tidyverse)
library(rethinking) #Web page, YouTube, Book
library(car) #regression diagnostics
#Data
#2016 overview: Inherent unpredictability: CHC lost 1/3 of games
#Objective is to predict who wins a game. Build model at level of a particular team.
#CHC schedule overview.
urlfile<-'https://raw.githubusercontent.com/blakeobeans/Bayesian-Baseball/master/Cubs/Season/cubs.csv'
data<-read.csv(urlfile)
View(data)
#Pitcher Stats
urlfile<-'https://raw.githubusercontent.com/blakeobeans/Bayesian-Baseball/master/Cubs/Pitching/pitching.csv'
pitcher<-read.csv(urlfile)
data<- left_join(data, pitcher,by="Pit")
View(pitcher)
#WL Record
urlfile<-'https://raw.githubusercontent.com/blakeobeans/Bayesian-Baseball/master/Cubs/Team%20Rankings/rankings.csv'
WL<-read.csv(urlfile)
data<- left_join(data, WL,by="Opp")
View(WL)
View(data)
#Transform Data
data$score <- data$R-data$RA #Positive score indicates Giants win. Beats logistic. No ties.
data$opp_team <- coerce_index(data$Opp) #ID for team (function from rethinking)
data$pit_id <- coerce_index(data$Pit) #Home pitcher
names(data) <- c("tm", "opp", "R", "RA", "pit", "pitera", "wl", "score",  "opp_team", "pit_id")
data$pitera_norm <-  (data$pitera - mean(data$pitera))/sd(data$pitera) #normalize ERA
data$wl_norm <-  (data$wl - mean(data$wl))/sd(data$wl) #normalize WL
data <- as.data.frame(data)
#Summary Stats
length(unique(data$opp_team)) # number of opposing teams; note 29 other in MLB
length(unique(data$pit)) # number of cubs pitchers
table(data$pit)# interesting margins, assume 1 per game
hist(data$score, prob=TRUE) #dist of scores
lines(density(data$score))
shapiro.test(data$score) #passes normality
#sort data
data <- data[order(data$opp_team),] #sort by team, note imbalance
#Linear Model 1- Team as Factor, no intercept. Not a bad fit!
lm1 <- lm(score ~ factor(opp) -1 , data= data); summary(lm1)
#Residual Plot
layout(matrix(c(1,2,3,4),2,2)) # optional 4 graphs/page
par(mfrow=c(2,2)) #better ordering of graphs
plot(lm1, which = 1:4)
shapiro.test(lm1$residuals)
#Predicting scores- factors, so not line of best fit
teams <- unique(data$opp)
newdata = data.frame(factor(teams)); names(newdata) <- 'opp'
lmdata <- predict(lm1, newdata, interval="predict")
games <- 1:20
lmdata <- as.data.frame(cbind(lmdata, 1:20))
names(lmdata) <- c("mean", "lwr", "upr", "opp_team"); head(lmdata)
#Plotting 95% intervals for each opposing team
par(mfrow=c(1,1))
plot(lmdata$opp_team, lmdata$mean, type = "n", ylim=c(-15, 15), main ="OLS Regression") #note enlarging y-axis
segments(lmdata$opp_team, lmdata$mean + lmdata$lwr, lmdata$opp_team, lmdata$mean + lmdata$upr)
points(data$opp_team, data$score, col = "red", pch=4)
points(lmdata$opp_team, lmdata$mean, col = "blue", pch=19)
abline(h = 0, col = "red")
set.seed(1234)
model <- map2stan(
alist(
score ~ dnorm( mu , sigma ) , #fair assumption given data
mu <- a[opp_team], #this is the regression equation/likelihood function
a[opp_team] ~ dnorm( 0 , 4 ), #what choice prior
sigma ~ dcauchy(0, 2.5) #prior to sigma
),
data=data, iter=6000, warmup=3000, chains=4)
#coefficients
head(precis(model, depth=2, prob=.95)) #OK that 0 in CI, similar sigma
#sample from posterior
postmodel <- extract.samples( model, n=5000)
postmodel.df <- as.data.frame(postmodel)
str(postmodel)
#Prior and Posterior- Note: does not account for group-level variance
par(mfrow=c(1,1))
dens( postmodel$a[,7], show.HPDI=0.95, main= "Cubs vs. Angels- Posterior of Mean Score") #POSTERIOR dist of means
x<-seq(from=-4, to=10, by=.1)
lines(x, dnorm(x, 0, 4), col="blue") #PRIOR Distribution
#Simulating posterior distributions all opposing teams
d.pred <- list(opp_team = 1:20)
#sim function to plot distribution of scores- This accounts for variance
sim.model <- sim( model , data=d.pred)
str(sim.model)
#CI for scores by team
pred.p <- apply( sim.model, 2 , mean); pred.p
pred.p.PI <- apply( sim.model, 2 , HPDI, prob=.95 ); pred.p.PI
pred.p2 <-as.data.frame(pred.p); head(pred.p2)
pred.p.PI2 <-as.data.frame(pred.p.PI); head(pred.p.PI2)
pred.p.PI2 <- t(pred.p.PI2); head(pred.p.PI2)
d<-cbind(pred.p2, pred.p.PI2, 1:20)
names(d) <- c("mean", "lower", "upper", "games"); head(d)
#Posterior Distributions
plot(d$games, d$mean, type = "n", xlab = "Opposing Team", ylab = "Score", ylim=c(-15,15), main= "MLM Regression")
segments(d$games, d$lower, d$games, d$upper)
abline(h = 0, col = "red")
points(data$opp_team, data$score, col = "red", pch=4)
points(d$games, d$mean, col = "blue", pch=19)
#compare intervals to standard regression
plot(lmdata$opp_team, lmdata$mean, type = "n", ylim=c(-15, 15), main ="OLS Regression") #note enlarging y-axis
segments(lmdata$opp_team, lmdata$mean + lmdata$lwr, lmdata$opp_team, lmdata$mean + lmdata$upr)
points(data$opp_team, data$score, col = "red", pch=4)
points(lmdata$opp_team, lmdata$mean, col = "blue", pch=19)
abline(h = 0, col = "red")
#Effect of MLM on mean, pooling effect across tanks
plot(d$games, d$mean, type = "n", xlab = "match", ylab = "score", ylim=c(-5,5), main="Pooling Effect of MLM")
points(lmdata$opp_team, lmdata$mean, col = "red", pch=1) #mean for standard regression
points(d$games, d$mean, col = "blue", pch=19) #mean for MLM
abline(h=mean(data$score), col = "blue")
#Posterior Distributions
plot(d$games, d$mean, type = "n", xlab = "Opposing Team", ylab = "Score", ylim=c(-15,15), main= "MLM Regression")
segments(d$games, d$lower, d$games, d$upper)
abline(h = 0, col = "red")
points(data$opp_team, data$score, col = "red", pch=4)
points(d$games, d$mean, col = "blue", pch=19)
#MLM. Pitcher ERA, WL record, how many levels in baseball?
#Note hyperparameters
standata <- data[,c("score", "opp_team", "pitera_norm", "wl_norm")]
View(standata)
set.seed(1234)
model2 <- map2stan(
alist(
score ~ dnorm( mu , sigma ) ,
mu <- a + a_team[opp_team] + b * pitera_norm + c * wl_norm,
sigma ~ dcauchy(0, 2.5),
a ~ dnorm(0,3),
a_team[opp_team] ~ dnorm( ai , as ), #adaptive prior from the data
ai ~ dnorm(0, 1),
as ~ dcauchy(0,2),
b ~ dnorm( 0, 1 ),
c ~ dnorm(0,1)
),
data=standata, iter=12000, warmup=3000, chains=4, cores=4)
#comparing models
compare(model, model2)
#coefficients
precis(model2, depth=2, prob=.95) #n_eff: number effective samples. R-hat: convergence to target dist.
coef <- precis(model2, depth=2, prob=.95)
coef2 <- slice(coef, c(1:2, 23:26))
variable <- c("sigma", "a", "ai", "as", "b", "c")
coef2 <- cbind(coef2, variable)
coef2 <-as.data.frame(coef2)
coef2 <- select(coef2, "variable", "mean", "sd", "2.5%", "97.5%", "n_eff", "Rhat")
#trace plot. Using monte carlo methods to "hill climb" and find the most likely parameter.
plot(model2)
#Predicting Game 1
d.pred <- list(
pitera_norm = -.929, #Lester
wl_norm = 1.29, #WL normalized for CLE (from WL dataset)
opp_team = 0) #placeholder
#Posterior Simulation
set.seed(1234)
sim.model <- sim( model2 , data=d.pred, n=12000)
sim <- as.data.frame(sim.model)
#Posterior Statistics
pred.p.mean <- apply( sim , 2 , mean ); pred.p.mean
pred.p.PI <- apply( sim, 2 , PI , prob=0.95 ); pred.p.PI
#Plot
par(mfrow=c(1,1))
histgm <- hist(sim$V1, breaks=100, prob=TRUE, main="Simulated Games", xlab="Score") #Distribution of predicted scores
histgm$counts=histgm$counts/sum(histgm$counts)
plot(histgm, col=ifelse(histgm$breaks >= 0, "green", "red"), main="Posterior Distribution of Outcomes Against CLE (Game 1)", xlab="Score", xlim=c(-12,12))
abline(v=0, col="blue")
prob_success <- sum(sim$V1 > 0)/nrow(sim); prob_success #percent of scores that are wins
sum(sim$V1 < 0)/nrow(sim) #percent of scores that are losses
#Win 4 out of 7
dbinom(4, size=7, prob=prob_success) + dbinom(5, size=7, prob=prob_success) + dbinom(6, size=7, prob=prob_success)+ dbinom(7, size=7, prob=prob_success)
pbinom(3, size=7, prob=prob_success, lower.tail = FALSE)
#Calculate the "Bayesian" R^2
library(rstanarm)
bayes_R2 <- function(fit) {
y <- get_y(fit)
ypred <- posterior_linpred(fit)
e <- -1 * sweep(ypred, 2, y)
var_ypred <- apply(ypred, 1, var)
var_e <- apply(e, 1, var)
var_ypred / (var_ypred + var_e)
}
#rstanarm model
M1 <- stan_lmer(score ~ wl_norm + pitera_norm + (1 | opp_team), data=data)
print(median(bayes_R2(M1)))
#Ratio of Variances (using lme4 package)
library(lme4)
fit1 <- lmer(score ~ wl_norm + pitera_norm + (1 |opp_team), data = data, REML = FALSE)
summary(fit1)
.256/17.23
#Shiny App
library(rstan)
library(shinystan)
library(rsconnect)
linkagecode <- stancode(model2)
set.seed(1234)
model_obj <- stan_model(model_code = linkagecode, model_name = "BayesianBaseball")
